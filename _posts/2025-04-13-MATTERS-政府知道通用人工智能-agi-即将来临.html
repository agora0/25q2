---
layout: post
title: 政府知道通用人工智能（AGI）即将来临
date: 2025-04-13 09:44:42.000000000 +00:00
link: https://matters.news/@conanxin/%E6%94%BF%E5%BA%9C%E7%9F%A5%E9%81%93%E9%80%9A%E7%94%A8%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD-agi-%E5%8D%B3%E5%B0%86%E6%9D%A5%E4%B8%B4-bafybeia624unm6sxyh2rzyrg2qajdirfn6iwgjgg7ccywxeegtfc2alxka
categories: matters
tags: blog
author: ConanXin
---

<p>过去几个月里，我经历了一件奇怪的事情：一个又一个来自人工智能实验室和政府的人找到我，说：这真的要发生了。我们即将实现<strong>通用人工智能</strong>。</p><p>他们的意思是，他们长期以来一直相信，我们正走在一条创造变革性<strong>人工智能</strong>的道路上，这种<strong>人工智能</strong>基本上能做任何人类在电脑前能做的事情——而且做得更好。他们曾认为这需要5到15年时间来开发。但现在他们相信，<strong>它将在两到三年内到来</strong>，也就是在<strong>唐纳德·特朗普（Donald Trump）</strong>的第二个任期内。</p><p>他们之所以相信这一点，是因为他们现在正在发布的产品，以及他们在工作场所内部看到的情况。而且我认为他们是对的。</p><p>如果你一直告诉自己这不会发生，我真的认为你需要质疑这种想法。这不是 Web3。这不是<strong>“雾件”（vaporware）</strong>。我们谈论的很多东西现在就已经在这里了。</p><p>我认为我们正处在人类历史上一个新时代的风口浪尖，这个时代不同于我们以往经历过的任何时代。而<strong>我们没有做好准备</strong>，部分原因是<strong>我们不清楚“做好准备”意味着什么</strong>。我们不知道它会是什么样子，会带来什么感觉。我们不知道劳动力市场将如何反应。我们不知道哪个国家会率先实现它。我们不知道它对战争意味着什么。我们不知道它对和平意味着什么。</p><p>尽管世界上还有很多其他事情值得关注，但我确实认为，很有可能，当我们回首人类历史的这个时代时，<strong>人工智能（A.I.）</strong>将被视为真正重要的那件事。</p><p>联系我的人之一是<strong>本·布坎南（Ben Buchanan）</strong>，他是<strong>拜登（Biden）政府</strong>白宫时期负责<strong>人工智能</strong>事务的前特别顾问。我认为邀请<strong>布坎南</strong>上节目会很有意思，原因有几个。</p><p>第一，他不是在人工智能实验室工作的人。所以，他并不是受大型<strong>人工智能</strong>实验室的雇佣来告诉你这项技术即将来临。</p><p>第二，他一直处于我们近年来制定的政策的核心地带——特别是那些旨在保持对华领先地位的政策。</p><p>第三，因为政府经历了深刻的更迭。新一届政府——包括<strong>埃隆·马斯克（Elon Musk）</strong>、<strong>马克·安德森（Marc Andreessen）</strong>、<strong>大卫·萨克斯（David Sacks）</strong>和<strong>J.D.万斯（JD Vance）</strong>——其中有很多人对<strong>人工智能</strong>持有非常强烈的看法。</p><p>我们正处于政策制定者大换届的时刻，而他们很可能在<strong>通用人工智能</strong>或类似事物冲击世界时掌权。那么，他们将要做什么？需要做出什么样的决策？我们现在需要开始进行什么样的思考，来为一个几乎所有该领域从业者都在竭尽全力、大声疾呼地告诉我们即将到来的事物做好准备？</p><p>————————————</p><p><strong>埃兹拉·克莱恩</strong>（Ezra Klein）：本·布坎南，欢迎来到节目。</p><p><strong>本·布坎南</strong>：谢谢邀请。</p><p>——</p><p><strong>埃兹拉·克莱恩</strong>：拜登政府任期结束后，我接到很多人的电话，他们想告诉我他们所做的所有伟大工作。但你打电话给我时，却是想警告人们你认为即将发生的事情。</p><p>即将发生的是什么？</p><p><strong>本·布坎南</strong>：我认为我们将看到能力超凡的<strong>人工智能</strong>系统。我不喜欢<strong>“通用人工智能”</strong>这个术语，但我认为这个术语在未来几年内将会适用，很可能就在<strong>唐纳德·特朗普</strong>的总统任期内。</p><p>有一种观点认为，<strong>通用人工智能（A.G.I.）</strong>一直以来多少都带有企业炒作或猜测的成分。而我在白宫工作时（当时我绝对不是在企业任职），看到的一件事就是趋势线看起来非常清晰。我们在<strong>拜登</strong>总统领导下试图做的，就是让美国政府和我们的社会为这些系统做好准备。</p><p>——</p><p><strong>埃兹拉·克莱恩</strong>：在我们讨论“做好准备”意味着什么之前，当你说“能力超凡的人工智能系统”时，你指的是什么？</p><p><strong>本·布坎南</strong>：通用人工智能（A.G.I.）的规范定义——再次强调，这是个我不喜欢的术语——是指一个系统——</p><p>——</p><p><strong>埃兹拉·克莱恩</strong>：如果你每次说 AGI 时都附带说明你不喜欢这个词，那就太好了。[笑]</p><p><strong>本·布坎南</strong>：这样大家就能记住了，对吧？[笑]</p><p>——</p><p><strong>埃兹拉·克莱恩</strong>：是的，人们会很喜欢这样。</p><p><strong>本·布坎南</strong>：埃兹拉，我正试图把它录入训练数据呢。</p><p><strong>通用人工智能（A.G.I.）</strong>的规范定义是：<strong>一个能够执行几乎任何人类可以完成的认知任务的系统。</strong>我不知道我们是否能在未来四年左右完全看到那样的系统，但我确实认为我们会看到类似的东西，其系统的广度惊人，深度也同样惊人，它有能力在某些情况下超越人类的能力，无论是在哪个认知领域——</p><p>——</p><p><strong>埃兹拉·克莱恩</strong>：那些能够在认知要求高的工作中取代人类的系统。</p><p><strong>本·布坎南</strong>：是的，或者取代认知工作的关键部分。是的。</p><p>——</p><p><strong>埃兹拉·克莱恩</strong>：我得说，我也非常确信我们正处在这个（变革的）风口浪尖。所以我并不是以<strong>怀疑者</strong>的身份来探讨这个问题。但我仍然觉得<strong>很难在思想上真正适应那个（即将到来的）世界</strong>。</p><p><strong>本·布坎南</strong>：我也是。</p><p>——</p><p><strong>埃兹拉·克莱恩</strong>：我最近使用了 Deep Research，这是 OpenAI 的一个新产品。它属于收费较高的服务层级。我想，大多数人还没有用过。但它能在几分钟之内生成一份更像科学分析简报的东西。</p><p>我在节目中与制作人合作。我雇佣极其有才华的人来做要求非常高的研究工作。我让 Deep Research 就<strong>麦迪逊式宪政体系</strong>与我们当前高度两极分化的全国性政党之间的紧张关系写一份报告。它在几分钟内生成的内容，至少达到了我合作过的任何团队在几天内所能产出成果的中等水平。</p><p>我和一些从事大量编程工作的公司的人聊过，他们告诉我，<strong>预计到今年年底或明年年底，大部分代码将不再由人类编写。</strong></p><p>我实在看不出这怎么可能不对劳动力市场产生影响。</p><p><strong>本·布坎南</strong>：我认为你说得对。我不是劳动力市场经济学家，但我认为这些系统的能力确实超凡。在某些方面，我非常赞同那句话：<strong>未来已来——只是分布不均。（</strong>The future is already here — it’s just unevenly distributed.<strong>）</strong></p><p>除非你亲自接触这项技术，否则你可能无法体会到它如今有多么出色。而且重要的是要认识到，<strong>今天就是它（未来发展中）表现最差的一天。它只会变得越来越好。</strong></p><p>而且我认为，这正是我们在白宫一直密切关注的动态——同时我也认为，下一届白宫乃至我们整个国家，都必须在极短的时间内去追踪并适应这一动态。</p><p>让我觉得很有意思的是，<strong>这基本上是第一个不由国防部资助的革命性技术</strong>。回顾历史，在过去大约一百年里，核武器、太空探索、互联网早期、微处理器早期、大型航空业早期、雷达、全球定位系统——这个清单非常非常长——所有这些技术基本上都源于国防部的资金支持。</p><p>诚然，是私营部门在进行发明创造。但是，（过去那种）中央政府的角色使得国防部和美国政府能够深入了解相关技术，而这种了解（政府）在人工智能领域默认是不具备的。这也赋予了美国政府塑造技术发展方向的能力，而这种能力我们在人工智能领域默认也是缺乏的。</p><p>——</p><p><strong>埃兹拉·克莱恩</strong>：在美国，关于人工智能存在很多争论。但有一点似乎得到了几乎普遍的认同，并且似乎是政策中占主导地位、起决定性作用的优先事项，那就是：我们必须赶在中国之前实现通用人工智能（AGI）。为什么？</p><p><strong>本·布坎南</strong>：我确实认为，实现<strong>通用人工智能（AGI）</strong>或<strong>变革性人工智能</strong>将带来深远的经济、军事和情报能力。而且我确实认为，美国在人工智能领域继续保持领先地位，对美国的国家安全至关重要。</p><p>我常常思考的一句话，实际上出自<strong>肯尼迪（Kennedy）</strong>1962年在<strong>莱斯大学（Rice University）</strong>发表的著名演讲：</p><blockquote><p>（约翰·F·肯尼迪档案录音片段）：我们选择在这十年内登上月球并完成其他事情，并非因为它们轻而易举，而是因为它们困难重重。</p></blockquote><p>每个人都记得这句话，因为他说的是我们要登上月球。但实际上，我认为他在谈论太空的重要性时，说出了更精彩的话。</p><blockquote><p>（约翰·F·肯尼迪档案录音片段）：因为空间科学，如同核科学和所有技术一样，其本身没有良知。它将成为造福人类还是贻害无穷的力量，取决于人类自身。只有当美国占据卓越地位时，我们才能帮助决定这片新的海洋将成为和平之海，还是一个新的可怕的战争舞台。</p></blockquote><p>我认为这同样适用于<strong>人工智能</strong>。这项技术存在着巨大的<strong>不确定性</strong>。</p><p>我不是<strong>人工智能</strong>的鼓吹者。我认为这项技术存在巨大风险。但我确实认为，美国在能够塑造其发展方向方面扮演着根本性的角色——这并不是说我们不想进行国际合作，也不是说我们不想与中国合作。</p><p>值得注意的是，在总统关于<strong>人工智能</strong>的行政命令中，有一条明确指出，我们愿意在<strong>人工智能安全</strong>等领域与竞争对手展开合作。但同样值得强调的是，我深切地认为，美国在这方面扮演着一个我们不能推卸的根本性角色。</p><p>——</p><p><strong>埃兹拉·克莱恩</strong>：请为我描绘一下具体情景。您说如果中国率先实现（AGI），将带来巨大的经济、国家安全和军事风险。请帮助听众/观众想象一下中国率先实现（AGI）的世界会是什么样子。</p><p><strong>本·布坎南</strong>：让我们来看一个狭窄的应用场景：将人工智能用于情报分析和网络行动。</p><p>众所周知，如果你拥有更强大的人工智能能力，那很可能会使你在网络攻击和防御方面都能做得更好。</p><p>什么是网络行动？就是侵入对手的网络以收集信息——如果你收集的信息量足够大，人工智能系统就可以帮助你进行分析。</p><p>实际上，我们通过国防高级研究计划局（D.A.R.P.A.）开展了一个名为<strong>“人工智能网络挑战赛”（A.I. Cyber Challenge）</strong>的大型项目，就是为了测试人工智能在这方面的能力。我绝不希望生活在这样一个世界：<strong>中国</strong>在网络攻击、防御方面拥有这种能力，而美国却没有。而且我认为，在许多对国家安全竞争至关重要的不同领域，情况都是如此。</p><p>——</p><p><strong>埃兹拉·克莱恩</strong>：我的感觉是，对于有能力的国家行为体来说，大多数人、大多数机构都是相当容易被入侵的。而现在，这些国家行为体的黑客攻击能力将会变得更强，并且他们将拥有更大的（攻击）规模。你可以拥有比人类黑客多得多的<strong>人工智能黑客</strong>。</p><p>作为普通人，我们是否即将进入一个在数字世界中更加脆弱的时代？我指的不仅仅是那些国家可能想要监视的人。而是各种不良行为者也将掌握这些系统的某些版本。</p><p>你是否担心这会演变成真正的反乌托邦景象？</p><p><strong>本·布坎南</strong>：当我们通常谈论<strong>黑客攻击</strong>时，指的是发现软件中的漏洞，并利用该漏洞获取非法访问权限。我认为，更强大的人工智能系统将使发现和利用漏洞、获取访问权限变得更加容易，这一点是正确的。而这将使进攻方占据优势。</p><p>我同时认为，在防御方面，更强大的人工智能系统也将使得从一开始就编写出更安全的代码、减少能够被发现的漏洞数量以及更好地检测到入侵的黑客变得更加容易。</p><p>我们（在政府时）曾尽可能地尝试将攻防平衡向防御方倾斜。但我认为，在未来几年，也就是我们一直在谈论的这个过渡期内，确实会存在一个阶段，那些不具备最新人工智能防御技术或软件开发技术优势的老旧遗留系统，整体而言，将更容易受到能力更强的攻击者的攻击。</p><p>——</p><p><strong>埃兹拉·克莱恩</strong>：而大多数人用的就是这种（老旧）系统。</p><p><strong>本·布坎南</strong>：实际上，我不确定这是否准确。你口袋里的 iPhone（会更新）。或者谷歌（安卓系统）会负责更新。</p><p>——</p><p><strong>埃兹拉·克莱恩</strong>：人们更新通常没那么及时。你的技术素养越低，就越容易受到这类风险的影响。</p><p><strong>本·布坎南</strong>：当然，我更多考虑的是那些遗留的电力系统和服务器主机，它们可能已经有二十年历史，并且一直持续运行。这才是我感觉风险最为严峻的地方。尽管当今大多数人个人技术平台的单一化（比如都用iOS或安卓）带来了风险，但其好处之一是这些平台确实会相当定期地推送安全更新。它们甚至通过推送包含新表情符号（emoji）的更新来吸引人们下载。</p><p>而且总的来说，现在的人们在给个人软件打补丁方面可能比15年前做得更好。</p><p>——</p><p><strong>埃兹拉·克莱恩</strong>：是啊，不更新的话会变得很烦人。</p><p>与此相对的是，很多人也担心人工智能实验室自身的安全问题。</p><p>对于其他国家来说，获取最新的 OpenAI 系统极具价值。这些公司的人——我跟他们谈过这事——说：一方面，这确实是个问题。但另一方面，采用真正安全的（工作）方式又确实很麻烦。</p><p><strong>本·布坎南</strong>：我曾在 SCIF——也就是“敏感信息隔离设施”（sensitive compartmented information facility）——工作了四年，那是一个安全房间，你不能带手机进去，诸如此类。那确实很烦人。毫无疑问。</p><p>——</p><p><strong>埃兹拉·克莱恩</strong>：你现在对人工智能（A.I.）实验室的脆弱性怎么看？</p><p><strong>本·布坎南</strong>：我对此感到担心。这里存在黑客攻击的风险。而且，如果你常去某些旧金山的家庭派对，（参与者）虽然不会分享模型本身，但他们会在某种程度上谈论他们使用的技术，而这些技术具有巨大的价值。</p><p>回到那个贯穿始终的思路，即人工智能是与国家安全相关、甚至可能改变世界的技术，但它并非来自政府的支持，也没有政府在安全要求方面的“官方认证”——这一点也通过这种方式显现出来。</p><p>在国家安全备忘录中，总统方面试图向这些实验室发出信号，并试图告诉他们：我们，作为美国政府，希望在这个任务中帮助你们。</p><p>这份（备忘录）是在<strong>2024年10月</strong>签署的，所以我们（当时的政府）没有太多时间在此基础上继续推进。但我认为这对于特朗普政府来说是一个优先事项。而且我无法想象还有什么比保护正在创造未来的美国公司更具无党派色彩的了。</p><p>——</p><p><strong>埃兹拉·克莱恩</strong>：关于信息处理，人们经常向我提及这其中一个有趣的维度。</p><p>与苏联和美国之间的间谍游戏相比，我们现在都拥有多得多的数据。我们拥有所有的卫星数据。显然，我们互相窃听，并且有各种各样这类信息涌入。</p><p>比我更了解情况的人告诉我，在由人类和分析这些数据的相当初级的程序来处理信息方面，存在一个巨大的瓶颈。因此，拥有这些能够“吸收消化”这些信息并进行模式识别的真正智能系统，是对力量平衡的一个非常重大的改变。</p><p><strong>本·布坎南</strong>：我认为我们（指政府）对此是相当公开的，<strong>拜登</strong>总统签署了一份国家安全备忘录——这基本上等同于国家安全领域的行政命令——其中指出：这是对美国至关重要的一个基础性领域。</p><p>我甚至不知道美国每天收集多少卫星图像，但数量是巨大的，而且我们已经公开表示过，我们根本没有足够的人手来审阅所有这些卫星图像。即使我们有足够的人手，那也会是一项极其枯燥繁重的工作。人工智能在浏览这些世界各地热点地区、航运线路等等的图像，以自动化方式进行分析，并将最有趣和最重要的图像筛选出来供人工审阅方面，可以发挥作用。</p><p>从一个层面看，你可以审视这个问题然后说：嗯，软件不就是做这个的吗？在某种程度上，这当然是真的。但在另一个层面，你可以说，软件能力越强，分析的自动化程度越高，你从数据中提取的情报优势就越大。而这最终会为美国带来更有利的地位。</p><p>——</p><p><strong>埃兹拉·克莱恩</strong>：其一阶和二阶后果同样引人注目。在一个拥有强大人工智能的世界里，进行间谍活动的动机增加了。因为如果我们目前收集的数据超出了我们的分析能力，那么我们收集的每一个边际数据片段（新增加的单个数据）就不是那么有价值了。</p><p><strong>本·布坎南：</strong>我认为这基本正确。我坚信，你需要有权利和保护措施，它们应该能够起到制约作用并表明：不，这里有一些关键类型的数据，包括关于本国公民的数据，以及在某些情况下，盟国公民的数据，即使有动机去收集，你也不应该收集。</p><p>尽管美国的情报监督程序存在种种缺陷，尽管我们可以就此展开各种辩论，但我们确实拥有这类（监督）结构。</p><p>而且，正如你所指出的原因，在拥有强大<strong>人工智能</strong>系统的时代，这一点（指拥有监督结构）变得根本上更加重要。</p><p>——</p><p><strong>埃兹拉·克莱恩</strong>：你对这一切的国家安全影响有多恐惧？包括它可能催生监控国家的可能性？</p><p>美国创新基金会（Foundation for American Innovation）的经济学家<strong>塞缪尔·哈蒙德（Samuel Hammond）</strong>几个月前写过一篇题为<strong>《关于人工智能的九十五条论纲》</strong>（<a target="_blank" rel="noopener noreferrer nofollow" class href="https://www.secondbest.ca/p/ninety-five-theses-on-ai">Ninety-Five Theses on A.I.</a>）的文章。他提出的一个我经常思考的观点是：如果我们拥有完美执法的能力，我们现行的许多法律就会变得非常束缚（难以承受）。</p><p>法律的制定是基于人类劳动力稀缺这一认知的。这就引出了一个问题：当监控国家变得非常高效时会发生什么？当人工智能使警察国家变成一种与现在截然不同的事物时会发生什么？当我们拥有无休止的无人机战争时会发生什么？</p><p>你现在经常听到<strong>安杜里尔（Anduril）</strong>这家公司。他们与 OpenAI 有合作关系。<strong>帕兰提尔（Palantir）</strong>与 Anthropic 有合作关系。我们即将看到一种真正的变化，从国家安全的角度来看，我认为这令人恐惧。</p><p>我理解为什么我们不希望中国远远领先于我们。但你如何看待它赋予我们自己政府的能力？</p><p><strong>本·布坎南：</strong>我会把这个关于人工智能与专制或监控国家的问题分解为两部分。</p><p>第一部分是关于中国的。在一个骨子里就是真正的专制国家、甚至对民主连伪装都懒得做的国家里，这会如何演变？</p><p>我想我们很快就能达成共识：这使得某种可能是他们社会核心渴望的东西——一种只有人工智能系统才能帮助实现的控制水平——变得非常具体真切。我只是觉得这太可怕了。</p><p>顺便说一句，俄语和中文里都有句谚语：“天高皇帝远”。（Heaven is high, and the emperor is far away）</p><p>历史上，即使在那些专制国家，由于国家幅员辽阔、疆域广袤，总存在某种国家权力无法侵入的空间。而在这些专制国家，人工智能可能会让政府权力的强制力变得更糟。</p><p>然后是在美国这个更有趣的问题：人工智能与民主之间的关系是什么？</p><p>我对此也感到有些不安。历史上曾有思想家说过，我们修订法律的部分方式就是当人们违反法律时。这其中存在一定的空间，而且我认为我们的司法体系中有一种人性化的东西，是我不希望失去的。</p><p>我们（指拜登政府）曾责成司法部启动一个流程来思考这个问题，并为在刑事司法中使用<strong>人工智能</strong>制定原则。在某些情况下，这样做有其优势——比如机器可以同等对待案件。</p><p>但同时也存在巨大的偏见、歧视等风险，因为这些系统存在缺陷，并且在某些情况下，因为这些系统无处不在。而且我确实认为，在执法系统中广泛且不受约束地使用人工智能，存在着从根本上侵犯权利的风险，对此我们应该高度警惕，而我作为一名公民，对此深感担忧。</p><p>——</p><p><strong>埃兹拉·克莱恩</strong>：我发现这一切都让我感到极度不安。原因之一是——该怎么说才恰当呢？——这就像我们试图与另一个几乎像是来自外星的盟友建立联盟，并且我们正与中国竞争以达成这个联盟。但我们不了解这个盟友，也不明白让这个盟友进入我们所有的系统和规划中意味着什么。</p><p>据我所知，每个真正致力于此的公司和政府都相信，在不远的将来，一旦人工智能变得更加自主，你将拥有更好、更快、更具主导性的决策循环。我们正奔向<strong>通用人工智能</strong>（AGI），却并不真正理解它是什么，或者它意味着什么。</p><p><strong>人工智能</strong>恰好在美国和中国陷入这种“修昔底德陷阱”式的超级大国主导权争夺的时刻走向成熟，这似乎是历史上潜在的危险事件。在这样的背景下创造地球智能的下一个转折点，其驱动因素是相当危险的。</p><p><strong>本·布坎南</strong>：是的，这里有很多需要梳理的内容。让我们按顺序来。</p><p>基本上，底线是：我在很大程度上也深感不安。出口管制的吸引力部分在于，它确定了一个可以有差别地减缓中国发展速度的“瓶颈点”，为美国创造领先的空间，并且在我看来，理想情况下，应将这种领先优势用于安全和协调，而不是盲目冒进——再次强调，这包括<strong>与中国进行潜在的协调</strong>，同时避免加剧这种军备竞赛的态势。</p><p>我不会说我们试图在国家安全应用方面争先恐后。国家安全备忘录中有相当长的篇幅描述了我们<strong>不会</strong>用人工智能系统做什么，以及一整套被禁止的用例和高风险用例清单。还有一个治理和风险管理框架——</p><p>——</p><p><strong>埃兹拉·克莱恩</strong>：是的，但你们（指拜登政府）已经不在位了。</p><p><strong>本·布坎南</strong>：嗯，这倒是事实。特朗普政府尚未废除这项（备忘录）。但我确实认为可以公平地说，在我们执政期间，我们试图为人工智能奠定的基础，是非常清楚地认识到你所说的在安全问题上“逐底竞争”（race to the bottom on safety）的动态。我们试图防范这种情况，即使在我们努力确保美国卓越地位的同时。</p><p>——</p><p><strong>埃兹拉·克莱恩</strong>：有人担心，通过将中国视为如此敌对的竞争对手——以至于我们采取包括先进技术出口管制在内的一切措施来阻碍他们——我们是否反而使他们变成了更激烈的竞争对手？这种担忧有道理吗？</p><p>我不想对中国的体制或中国共产党的意识形态抱有天真想法。他们想要实力和主导地位，并希望下一个时代是中国的时代。所以也许你对此无能为力，但是试图切断供应给另一个最大国家、作为下一个时代核心技术的芯片，这确实是相当具有敌意的。</p><p><strong>本·布坎南</strong>：我不认为说我们不向你出售世界上最先进的技术就等同于相当有敌意。那不是宣战。其本身也不是冷战宣言。我认为这只是在说：<strong>这项技术极其重要。</strong></p><p>——</p><p><strong>埃兹拉·克莱恩</strong>：你认为他们是这样理解的吗？</p><p><strong>本·布坎南</strong>：这可能比你想要的更学术化，但我刚开始做教授时的学术研究基本上就是关于“修昔底德陷阱”，或者我们在学术界称之为“安全困境”（security dilemma），即国家之间如何相互误解。所以我确信，在这个领域，中国和美国在某种程度上是相互误解的。</p><p>但我认为对事实的直接解读是，我不认为不向他们出售芯片就是宣战——</p><p>——</p><p><strong>埃兹拉·克莱恩</strong>：但我不认为他们误解了我们。听着，我知道华盛顿的政治是如何运作的。我看到了（美国）转向与中国采取更具对抗性的姿态。我知道<strong>杰克·沙利文（Jake Sullivan）</strong>和<strong>拜登总统</strong>想称之为“战略竞争”而非“新冷战”。我理解这一切，而且我认为这是事实。</p><p>但我们刚才谈到——而且你没有反驳这一点——我们的主导观点是，我们需要在他们之前获得这项技术。我不认为中国看待这件事会像是：“哦，没有人会把顶级技术卖给我们。”</p><p>我认为他们明白我们在这里做什么。</p><p><strong>本·布坎南</strong>：在某种程度上——我不想粉饰太平——我确信他们确实是这样看的。</p><p>另一方面，我们与中国建立了人工智能对话机制。我飞往日内瓦与他们会面，我们试图与他们讨论人工智能安全等问题。所以我确实认为，在像人工智能这样复杂的领域，可以同时存在多种真实情况。</p><p>我一秒钟也不后悔实施出口管制。而且坦率地说，我们为在当时实施了这些管制而感到自豪，因为它帮助确保了几年后，我们仍然在人工智能领域保持优势——尽管 DeepSeek 表现得再好、再有才华。</p><p>——</p><p><strong>埃兹拉·克莱恩</strong>：我认为 DeepSeek 之所以对美国体系（认知）造成如此大的冲击，是因为它似乎是用少得多的算力、少得多的资金训练出来的，并且能在高水平上与我们的前沿系统竞争。</p><p>你是如何理解 DeepSeek 是什么，以及它要求我们重新思考哪些假设的？</p><p><strong>本·布坎南</strong>：让我们退一步，追溯一下 DeepSeek 的历史。</p><p>我们在白宫从 2023 年 11 月左右就开始关注 <strong>DeepSeek </strong>了，当时他们发布了第一个编码系统。毫无疑问，DeepSeek 的工程师非常有才华，他们在整个 2024 年期间不断改进他们的系统。</p><p>当他们的首席执行官表示，<strong>DeepSeek </strong>面临的最大障碍不是无法获得资金或人才，而是无法获得先进芯片时，我们感到鼓舞。尽管很明显他们仍然得到了一些芯片——有些是合法购买的，有些似乎是走私的。</p><p>2024 年 12 月，他们推出了一个名为 DeepSeek-V3 的系统，这实际上是本应引起关注的那个。它没有引起太多关注，但确实表明他们在算法上取得了强劲进展，并且基本上在使系统更有效率。</p><p>然后在 2024 年 1 月，他们推出了一个名为 DeepSeek-R1 的系统。R1 实际上并不那么不寻常。没有人会期望作为一个扩展底层 V3 系统的推理系统，它需要大量的算力。</p><p>这说了很多技术术语。但这里的关键是，当你审视 DeepSeek 所做的事情时，我不认为围绕它的媒体炒作是合理的，而且我不认为它改变了我们（美国）正在做的事情的基本分析。</p><p>他们仍然受到算力的限制。我们应该加强限制并继续限制他们。他们很聪明。他们的算法在进步。但美国公司的算法也在进步。</p><p>这应该提醒我们，芯片管制很重要，中国在这里是一个值得重视的竞争对手，我们不应该想当然。但我认为现在还不是说天要塌下来了，或者说基本的规模定律（scaling laws）已被打破的时候。</p><p>你认为他们的性能提升是从哪里来的？我们读了他们的论文。他们是聪明人，正在做着与谷歌、Anthropic 和 OpenAI 等公司完全相同的算法效率工作。</p><p>——</p><p><strong>埃兹拉·克莱恩</strong>：我从左派那里听到的一个普遍论点是——<strong>莉娜·可汗（Lina Khan）</strong>就提出了这一点——DeepSeek 证明了我们整个人工智能发展的范式是错误的：我们不需要所有这些算力，我们不需要这些庞大的巨型公司，DeepSeek 展示了一条通往去中心化的、近乎 solarpunk 式的人工智能发展道路。而且，在某种意义上，美国的体系和想象力已经被这三家大公司所禁锢。</p><p>但我们从中国看到的是：那（指大量算力、大公司模式）并非必需。我们可以在更少的能源、更少的芯片、更少的（资源）足迹上做到这一点。</p><p>你认同（那个左派的观点）吗？</p><p><strong>本·布坎南</strong>：我认为这里有两点是真实的。第一，至少在可预见的未来，总会有一个前沿领域。会有一个需要大量计算和能源的前沿领域。我们希望我们的公司处于这个前沿。</p><p>这些公司有非常强烈的动机去寻求效率提升，而且它们都在这样做。它们都想从每一次计算中榨取最后一滴洞察力。但它们将需要继续推动前沿。</p><p>然后，除此之外，会有一个滞后于前沿的、更缓慢的扩散过程，在这个过程中，算法变得更有效率，所需的计算机芯片更少，所需的能源也更少。我们需要在这两个竞争中都取得胜利。</p><p>——</p><p><strong>埃兹拉·克莱恩</strong>：人工智能公司希望实行出口管制，但半导体公司不希望。DeepSeek 通过让人们质疑英伟达（Nvidia）的长期价值而震动了美国股市。英伟达非常不希望实行这些出口管制。</p><p>你曾在白宫，处于这一系列来回游说的中心。你是怎么看待这个问题的？</p><p><strong>本·布坎南</strong>：每一块生产出来的先进人工智能芯片都会被卖掉。目前以及我认为在可预见的未来，这些芯片的市场需求都非常旺盛。所以我认为我们的观点是，我们实施了出口管制——</p><p>——</p><p><strong>埃兹拉·克莱恩</strong>：等等，但英伟达不这么认为。股市也不这么认为。</p><p><strong>本·布坎南</strong>：我们在 2022 年 10 月实施了第一轮出口管制。自那时以来，英伟达的股价已经涨了 10 倍。</p><p>——</p><p><strong>埃兹拉·克莱恩</strong>：我不是说我们不应该实施出口管制。但我希望你接受这个论点的强力版本，而不是弱化版本。我不认为英伟达的首席执行官说“如果英伟达不能向中国出口其顶级芯片，从长远来看将减少英伟达芯片的市场”是错的。</p><p><strong>本·布坎南</strong>：当然。我认为这个动态是正确的。如果他们有更大的市场，他们可以在边际上收取更高的价格。这显然是供需关系。</p><p>我认为我们的分析是：考虑到这些芯片及其制造的人工智能系统对美国国家安全的重要性，这是一个值得付出的权衡。</p><p>再次强调，自从我们实施出口管制以来，英伟达的表现一直非常好。即使在 DeepSeek 事件之后，英伟达目前的市盈率大约是 50 倍。所以市场仍然预期他们会增长。我也同意这一点。</p><p>——</p><p><strong>埃兹拉·克莱恩</strong>：拜登政府通常也关注人工智能安全。我认为它受到了关心人工智能安全人士的影响。而这引发了这场辩论中<strong>加速主义（accelerationist）</strong>一方的强烈反对。</p><p>我想为你播放一段<strong>马克·安德森（Marc Andreessen）</strong>的录音片段，他是一位著名的风险投资家，也是<strong>特朗普</strong>的高级顾问。他描述了他与拜登政府就人工智能进行的对话，以及这些对话如何使他在相反的方向上变得激进。</p><blockquote><p>（马克·安德森档案录音片段）：本（霍洛维茨，Ben Horowitz）和我在 2024 年 5 月去了华盛顿。我们没能见到拜登，因为事实证明，当时谁也见不到拜登。但我们得以与高级幕僚会面。所以我们会见了白宫核心圈层的非常高级别的人员。我们基本上转达了我们对人工智能的担忧。他们给我们的回应是：是的，正如我们将在拜登政府第二任期实施的那样，关于人工智能的国家议程是：我们将确保人工智能只由两到三家大公司掌控。我们将直接监管和控制这些公司。不会再有初创公司。你们以为可以随便创办公司、编写代码并发布到互联网上的那种日子结束了。那不会发生。</p></blockquote><p>你是否参与了他所描述的那次对话？</p><p><strong>本·布坎南</strong>：我与他见过一次面。我不确定具体是哪次——</p><p>——</p><p><strong>埃兹拉·克莱恩</strong>：他描述的内容符合你与他那次对话的情况吗？</p><p><strong>本·布坎南</strong>：他谈到了与初创企业和竞争力相关的担忧。我认为我的观点是：你看看我们在竞争力方面的记录，很明显我们想要一个充满活力的生态系统。</p><p>特朗普总统刚刚废除的<strong>人工智能</strong>行政命令中，有相当长的一部分是关于竞争力的。管理和预算办公室（OMB）关于美国政府如何采购人工智能的备忘录中，也特别强调了一点，说：我们希望从各种各样的供应商那里采购。</p><p>《芯片与科学法案》（CHIPS and Science Act）中也有很多关于竞争的内容。</p><p>所以我认为我们在竞争问题上的观点是相当明确的。不过我确实认为，存在一些与规模定律（scaling laws）等相关的结构性动态，会迫使事物向大公司集中，而在很多方面，我们（指拜登政府）正是反对这种趋势的。但我认为我们在竞争方面的过往记录是相当清晰的。</p><p>——</p><p><strong>埃兹拉·克莱恩</strong>：我理解安德森所反对的观点——这个观点我从人工智能安全社区的人那里听到过，但不一定是我从拜登政府那里听到的——是，当最大实验室的前沿模型变得足够强大时，你需要对其进行监管。</p><p>而为了做到这一点，你需要对这些模型进行控制。你不能让模型和所有东西都随意流传，以至于每个人都可以在自己的家用笔记本电脑上运行它。</p><p>我认为这正是他所指的紧张关系。它触及了一个更大的紧张关系，即对于这项极其强大且快速变化的技术，应该在多大程度上进行监管，以便一方面确保其安全，另一方面又不过度减缓其发展速度，或者不至于让小型公司在使用越来越强大的系统时无法遵守这些新规定。</p><p><strong>本·布坎南</strong>：在总统的行政命令中，我们实际上试图努力解决这个问题，但在 2023 年 10 月签署该命令时，我们还没有答案。</p><p>特别是在开源问题上我们所做的——我认为我们在这里应该精确一点，冒着再次变得学术化的风险：但我们谈论的是“开放权重”（open-weight）系统。</p><p>——</p><p><strong>埃兹拉·克莱恩</strong>：你能解释一下在这个语境下，“权重”（weights）和“开放权重”（open weights）是什么意思吗？</p><p><strong>本·布坎南</strong>：在人工智能系统的训练过程中，你通过巨大的算力运行一个算法来处理数据。粗略地说——我强调这是最不严谨的比喻——训练过程结束时的输出，大致类似于你大脑中神经元之间连接的强度。在某种意义上，你可以将其视为原始的人工智能系统。</p><p>当你拥有这些“权重”时，像 Meta 和 DeepSeek 这样的公司有时会选择将它们发布到互联网上，这就使它们成为了我们所说的“开放权重”系统。</p><p>“开放权重”系统的一个关键之处在于，好的一面是，基于这个系统进行创新、作为未来系统的基础要容易得多，因为你接触到了原始的东西。</p><p>也许风险更大的一面是：内置于该系统的任何安全防护措施——比如说，拒绝用户请求帮助开发生物武器——都相当容易被移除。</p><p>我是开源生态系统的坚定支持者。许多发布其系统权重的公司并没有将它们开源。他们不发布代码等等。所以我认为不应该给他们冠以“开源系统”的荣誉——冒着有点迂腐的风险。</p><p>但“开放权重”系统是我们 在 23 年和 24 年思考了很多的问题。我们发出了一个范围相当广泛的意见征询。我们收到了很多反馈意见，而在 24 年 7 月左右发布的报告中，我们得出的结论基本上是：目前还没有证据表明需要限制开放权重生态系统。开放权重生态系统对创新等有很大贡献，我认为这显然是事实。但随着技术的进步，我们应该继续监测这个问题。</p><p>基本上就是你描述的那样。</p><p>——</p><p><strong>埃兹拉·克莱恩</strong>：当你们收到那些评论时，不仅是关于开放权重模型的，也包括当你们与这些实验室的负责人交谈时，他们想要什么？如果说人工智能界存在共识的话，你会说他们认为需要什么才能快速达到目标（AGI）？</p><p>还有——因为我知道这些实验室里的许多人担心如果这些系统不安全会意味着什么——你会如何描述他们在安全问题上的共识？</p><p><strong>本·布坎南</strong>：我之前提到过这个核心的智识洞见：这项技术——也许是长期以来的第一次——是一项革命性的、但并非由政府资助的技术。在其早期的孵化阶段，这就是来自实验室的主题——一种类似：“难道你不知道我们正在发明一种非常强大的东西吗？最终，它将对你们在国家安全领域的工作以及我们组织社会的方式产生影响。”</p><p>与其说是任何具体的政策要求，他们基本上是在说：为这个做好准备。</p><p>我们所做的最接近任何形式监管的事情是，在实验室做出进行安全测试的自愿承诺之后，我们说：你们必须与我们分享那些安全测试结果，并且你们必须帮助我们了解技术的发展方向。</p><p>这只适用于顶尖的几家实验室。这些实验室事先并不知道会有这个要求，而且当它出台时，并非所有人都对此感到兴奋。</p><p>所以那种认为这是某种<strong>“监管俘获”（regulatory capture）</strong>——即我们是被要求这样做的——的说法根本不属实。</p><p>但在我的经历中，我从未收到来自实验室的个别政策游说。我收到的更多是：这（AGI）要来了。它比你想象的来得快得多。确保你们做好准备。</p><p>如果说他们确实在要求什么具体的东西，那也是由此引申出来的：我们将需要大量的能源，我们想在美国本土进行（研发和部署），但在美国获得电力真的很难。</p><p>——</p><p><strong>埃兹拉·克莱恩</strong>：但这已经成了一个相当大的问题。如果这一切真的像我们认为的那样强大，而你最终把大量包含所有模型权重和其他东西的数据中心建在了，比如说，一堆中东石油国家——因为他们会为你提供大量的能源接入，以换取在这个人工智能世界中获得一些影响力——这个问题确实值得关注。</p><p><strong>本·布坎南</strong>：是的。这实际上是一个两党达成共识的领域。</p><p>我们在 23 年后期和 24 年的大部分时间里，开始真正密切关注这个问题，当时很明显这（能源供应）将成为一个瓶颈。</p><p>在他离任前的最后一周左右，拜登总统签署了一项关于人工智能基础设施的行政命令，该命令尚未被废除，其基本目的是为了加速美国本土的电力发展以及电力和数据中心的审批，原因基本上就是你提到的那个。</p><p>作为一个真正相信气候变化、环境保护主义和清洁能源的人，我认为这样做有双重好处，那就是如果我们在美国这样做，它可以催化清洁能源转型。而且这些（AI）公司，出于各种原因，愿意为清洁能源以及像地热能这样的东西支付更高的价格。</p><p>我们的希望是，我们可以催化这种发展，降低成本曲线，让这些公司成为该技术的早期采用者，这样我们也能在气候方面取得胜利。</p><p>——</p><p><strong>埃兹拉·克莱恩</strong>：围绕如何为人工智能做准备，存在着相互冲突的文化——我提到了人工智能安全（A.I. safety）和<strong>人工智能加速主义（A.I. accelerationism）</strong>。</p><p>J.D. 万斯（JD Vance）刚刚参加了在巴黎举行的大型人工智能峰会。我来播放一段他说的话：</p><blockquote><p>（J.D. 万斯档案录音片段）：当像这样的会议召集起来讨论一项前沿技术时，我认为我们的反应往往过于顾虑重重、过于规避风险。但我从未遇到过一项技术突破，如此清晰地要求我们采取恰恰相反的做法。</p></blockquote><p>你对此怎么看？</p><p><strong>本·布坎南</strong>：我认为他在这里设定了一个我不太认同的二元对立。具有讽刺意味的是，如果你看看他演讲的其余部分——我确实看了——实际上有很多内容我是同意的。</p><p>例如，我认为他的演讲中有四个支柱。一个是关于将工人的重要性置于中心。一个是关于美国的卓越地位。</p><p>而这些与我们（指拜登政府）采取的行动以及我认为我曾参与的政府所倡导的、并且我本人也坚信的理念是完全一致的。</p><p>就他认为安全与机遇之间存在根本性紧张关系而言，我不同意。如果你回顾技术和技术适应的历史，证据相当清楚地表明，适量的安全行动会释放机遇，并且实际上会加速发展。</p><p>我们研究了很多并与总统讨论过的例子之一是铁路发展的早期。当时发生了大量的事故、撞车和死亡事件。结果导致人们不愿意使用铁路。</p><p>后来开始出现的是安全标准和安全技术：闭塞信号系统，让火车知道它们何时处于同一区域；空气制动器，让火车能够更有效地制动；火车轨道宽度和轨距等的标准化。</p><p>这在当时并不总是受欢迎的，但事后看来，非常清楚的是，那种技术以及在某种程度上安全标准的政策发展，造就了 19 世纪末的美国铁路系统。而这是在整个技术史上反复出现的模式。</p><p>需要非常明确的是，并非每一项针对每种技术的安全法规都是好的。当然也存在过度干预、拖慢速度、扼杀发展的情况。但我认为安全与机遇之间存在根本性的紧张关系是不正确的。</p><p>——</p><p><strong>埃兹拉·克莱恩</strong>：这很有趣，因为我不知道如何把握好监管的尺度。</p><p>我认为对副总统万斯的观点的反驳是核能。核能是一项既曾带来巨大希望、或许现在仍然如此的技术。而且你真的可以想象每个国家都想在这方面领先。</p><p>但是一系列的事故——其中大多数甚至没有造成特别重大的伤亡——让人们如此恐惧，以至于这项技术受到了严格的监管，以至于核能倡导者认为，与它本可以达到的程度相比，它在很大程度上被扼杀在了摇篮里。</p><p><strong>本·布坎南</strong>：那么问题就是：当你审视我们在人工智能方面采取的行动时，我们是否在扼杀它于摇篮之中，我们采取的行动是否类似于——</p><p>——</p><p><strong>埃兹拉·克莱恩</strong>：我不是说我们已经这样做了。看，如果这些系统将变得更加强大，并将负责更多的事情，那么事情既会出错，也会变得怪异。在一个像人类社会这样复杂的系统中推广如此新颖的事物，不可能不是这样。</p><p>所以就会有这样一个问题：什么样的制度能让人们在经历那类（出错或怪异的）时刻后，仍然感到安心地继续前进？</p><p><strong>本·布坎南</strong>：我认为这是一个深刻的问题。我们在拜登政府试图做的，就是在政府内部建立机构，以尽可能清醒、精通技术的方式来做这件事。</p><p>再次强调，除了共享安全测试结果——一些首席执行官估计这花费了他们一天的员工工作量——之外，我们没有实施任何接近监管的措施。</p><p>我们创建了一个名为<strong>“美国人工智能安全研究所”</strong>（U.S. Artificial Intelligence Safety Institute）的机构，它纯粹关注国家安全——网络风险、生物风险、人工智能事故风险——并且是纯粹自愿参与的，它与 Anthropic、OpenAI，甚至与埃隆（马斯克）的 xAI 公司都建立了关系，签署了谅解备忘录。</p><p>基本上我认为我们将其视为一个将人工智能专业知识引入政府的机会。以自愿的方式在公共和私营部门之间建立关系。随着技术的发展，现在将由特朗普政府来决定他们想用它做什么。</p><p>——</p><p><strong>埃兹拉·克莱恩</strong>：但我认为你相当外交辞令地低估了这里存在的真正分歧。</p><p>我认为<strong>万斯</strong>的演讲所传递的信号是，政府内部围绕人工智能出现了一种不同的文化。一直以来存在一种人工智能安全文化，我们举办所有这些会议讨论可能出错的地方。</p><p>而<strong>万斯</strong>在说：别这样了。是的，也许事情会出错。但我们应该专注于可能向好的方面发展。</p><p>坦率地说，我认为这是<strong>特朗普-马斯克政府</strong>的普遍观点——我认为在某种程度上，这是思考本届政府的正确方式。<strong>那就是如果出了问题，我们事后再处理那个问题。</strong>但你不想做的是因为担心出问题而行动过于缓慢。打破东西然后修复它们，比为了不打破东西而行动过于缓慢要好。</p><p><strong>本・布坎南</strong>：我认为公平地说，特朗普政府和我们在某些事情上确实存在文化差异。</p><p>但我们也举办过关于人工智能能做什么以及人工智能益处的会议。我们一直谈论需要减轻这些风险，但你这样做是为了能够抓住机遇。</p><p>而且我读了像 <strong>Anthropic </strong>首席执行官<strong>达里奥·阿莫迪（Dario Amodei）</strong>写的<strong>《慈爱机器》（Machines of Loving Grace）</strong>这样的文章——这篇文章基本上是关于人工智能的好处的——我也会说：这里面有很多我们可以认同的地方。</p><p>总统的行政命令说我们应该在行政部门更多地使用人工智能。所以我理解你说的文化差异。我明白。但我认为当落实到具体行动时，我们对于“既能抓住人工智能的机遇，又能安全地进行”这一理念是感到舒适的。</p><p>现在他们掌权了，他们将不得不决定如何将副总统万斯的言论转化为执政政策。我对他们行政命令的理解是，他们给了自己六个月的时间来弄清楚他们要做什么。我认为我们应该根据他们实际做的事情来评判他们。</p><p>——</p><p><strong>埃兹拉·克莱恩</strong>：让我问问这个问题的另一面。我喜欢<strong>万斯</strong>演讲的一点是：我认为他说得对，我们对机遇谈得不够多。但更重要的是，我们没有为机遇做准备。</p><p>如果你想象人工智能将产生其支持者和倡导者所希望的影响和可能性，那么其中一点就意味着：我们将开始以更快的速度发现或提出新的药物分子。这是一个非常有前景的领域。</p><p>根据我与之交谈过的人的说法，这里的想法是，<strong>人工智能</strong>应该能够吸收大量信息，并建立人体内疾病的模型，从而为我们带来更好的药物发现流程。</p><p>如果这是真的，你可以问：瓶颈会在哪里？</p><p>我们的药物测试流程极其繁琐。很难获得试验所需的动物，也很难获得试验所需的人类志愿者。你可以做很多事情来加快这个流程。</p><p>在许多不同的领域都是如此——教育等等。很明显，瓶颈将变成在现实世界中做事情的难度。而我没有看到社会为此做准备。也许我们在安全方面做得不多，因为我们不知道该做什么。</p><p>但在<strong>机遇方面</strong>，如何真正实现快速转化人工智能益处的这个问题，似乎比我所见过的任何严肃讨论都要丰富得多。</p><p><strong>本·布坎南</strong>：我基本上完全同意这一切。当我们在政府时，尤其是在 23 年和 24 年，相关的对话已经开始发生。我们研究了临床试验的事情。</p><p>你写医疗保健已经很久了，我不敢自称是医疗保健专家。但在我看来，我们确实希望达到这样一个世界：我们可以将突破，包括来自<strong>人工智能</strong>系统的突破，更快地转化为市场应用。</p><p>这不是假设性的事情。值得注意的是，就在最近，谷歌推出了——我想他们称之为“协同科学家”（co-scientist）。英伟达和做了出色工作的 Arc 研究所推出了有史以来最令人印象深刻的生物设计模型，它对生物分子有了更详细的理解。一个名为 FutureHouse 的组织在科学领域也做了同样出色的工作。</p><p>所以我认为这不是假设。这正在发生。我同意你的看法，在制度上和组织上可以做很多事情，让联邦政府为此做好准备。</p><p>——</p><p><strong>埃兹拉·克莱恩</strong>：我这周在华盛顿特区四处走动，与许多参与<strong>特朗普政府</strong>的人交谈——他们来自我所认为的<strong>现代右翼</strong>的不同派别。</p><p>我很惊讶有这么多人理解特朗普、马斯克和 DOGE。正在做什么，或者至少理解它最终将允许什么，并且认为这与<strong>人工智能</strong>相关——包括那些并非科技右翼、我本不指望从他们那里听到这些的人。</p><p>他们基本上是说：联邦政府过于臃肿，无法利用人工智能这项技术。因此，如果人工智能的全部意义在于加速认知工作，那么政府就需要被精简和重建，以便利用人工智能——这一点，不管你喜欢与否，正是马斯克和 DOGE 正在做的。而政府的拆解允许一种创造性破坏，为政府更好地利用<strong>人工智能</strong>铺平道路。</p><p>你认同这种说法吗？</p><p><strong>本·布坎南</strong>：这与我对 <strong>DOGE </strong>的观察似乎大相径庭。我认为<strong>马斯克</strong>确实理解人工智能能做什么，但我不知道从<strong>美国国际开发署（USAID）</strong>着手，如何能让美国政府制定出更好的人工智能政策。</p><p>所以我想我不认同这是 DOGE 的动机。</p><p>——</p><p><strong>埃兹拉·克莱恩</strong>：但这个更广泛的论点是否有道理呢？我得说，我不认同关于 DOGE 的论点——我会提出和你刚才一样的观点。</p><p>但我确实认同的是，我很了解联邦政府的运作方式，它在技术现代化方面过于缓慢。它在跨部门协作方面过于缓慢。而且它在彻底改变做事方式并利用那些能提高生产力的事物方面过于缓慢。</p><p><strong>本·布坎南</strong>：我完全同意。我的工作——<strong>白宫人工智能特别顾问</strong>（现在由<strong>大卫·萨克斯</strong>担任，我在 2023 年担任此职）——的存在，就是因为拜登总统非常明确地公开和私下表示：我们不能以典型的政府节奏行动。我们在这里必须行动得更快。</p><p>我想我们可能需要谨慎，我不是来主张全盘推倒重来的。但我同意你的看法。我们必须行动得更快。</p><p>——</p><p><strong>埃兹拉·克莱恩</strong>：万斯副总统演讲的另一个主要部分是向欧洲人发出信号，表示我们不会签署可能拖慢我们步伐的复杂多边谈判和法规——并且如果他们通过了惩罚我们人工智能公司的此类法规，我们将进行报复。</p><p>你如何看待新政府相对于欧洲正在采取的不同立场，以及其对科技监管的总体方针？</p><p><strong>本·布坎南</strong>：我认为坦率地说，我们与欧洲就他们起草欧盟《人工智能法案》进行了对话。</p><p>当时我在欧盟（处理相关事务时），《人工智能法案》尚处于初期阶段。法案已经通过，但许多实际细节被推到了一个仍在进行中的流程中。所以——</p><p>——</p><p><strong>埃兹拉·克莱恩</strong>：说到行动缓慢的官僚机构。</p><p><strong>本·布坎南</strong>：正是。所以也许这是我的失职，但我没有与欧洲人进行特别详细的对话，除了大致阐述我们的观点之外。他们很尊重我们。我们也很尊重他们。但我认为公平地说，我们采取了与他们不同的方法。就安全与机遇是二元对立而言——我认为它们并非纯粹的二元对立——我们准备在人工智能发展方面快速前进。</p><p>——</p><p><strong>埃兹拉·克莱恩</strong>：万斯谈到的另一件事，也是你表示同意的，是让AI“有利于工人”。这（pro-worker）意味着什么？</p><p><strong>本·布坎南</strong>：这是个至关重要的问题。我们将这一点体现在几个不同的原则中。第一是，工作场所中的<strong>人工智能</strong>需要以尊重工人的方式实施。</p><p>我知道总统深入思考过的一件事是，<strong>人工智能</strong>如何可能以一种非人化、有辱人格且最终对工人具有破坏性的方式让工作场所变得更糟。所以这是其中第一个我不想忽视的独特部分。</p><p>第二是：我认为我们希望<strong>人工智能</strong>在我们的整个经济中部署，以提升工人的能动性（agency）和能力。而且我认为我们应该坦诚地承认，由于<strong>人工智能</strong>，经济将发生大量转型。</p><p>我不知道那会是什么样子。你可以找到诺贝尔奖得主经济学家说影响不会很大。你也可以找到其他人说影响会非常大。我倾向于认为会很多。但我不是劳工经济学家。</p><p><strong>万斯副总统</strong>使用的措辞与<strong>拜登总统</strong>使用的完全相同，那就是：<strong>在转型中给予工人一席之地。</strong></p><p>我认为这是我们试图做的根本部分，而且我推测，也是他们（指特朗普政府）试图做的。</p><p>——</p><p><strong>埃兹拉·克莱恩</strong>：我听你以“不是劳工经济学家”为由回避这个问题。</p><p><strong>本·布坎南</strong>：我不是劳工经济学家，埃兹拉。[笑]</p><p>——</p><p><strong>埃兹拉·克莱恩</strong>：我向你保证，劳工经济学家们也不知道如何应对人工智能。你是人工智能首席顾问。你处于政府关于未来发展信息的中枢神经。如果这件事有你似乎认为的一半那么严重，考虑到它到来的时间跨度如此之短，它将是对劳动力市场有史以来最具颠覆性的事件。</p><p>铺设电力花了很长时间。修建铁路花了很长时间。<strong>人工智能</strong>将非常迅速地到来。</p><p><strong>本·布坎南</strong>：这基本正确，但我想稍微反驳一下。我确实认为我们将看到一种动态，即它将首先冲击经济的某些部分。它将首先冲击某些公司。但它将在整个社会中分布不均。</p><p>——</p><p><strong>埃兹拉·克莱恩：</strong>嗯，我认为它会是不均衡的，而这正是其部分破坏稳定性的原因。</p><p>让我给你举一个我担心的那种情况的例子。现在大学里有很多 19 岁的学生在学市场营销。而坦率地说，<strong>人工智能</strong>现在就能完美胜任很多市场营销工作。</p><p>随着我们越来越懂得如何指导<strong>人工智能</strong>，我的意思是，<strong>拖慢这一进程的事情之一仅仅是公司的适应过程</strong>。但将很快发生的事情是，你会看到围绕人工智能建立的公司。</p><p>大公司整合它会更难，但你将看到的是从零开始建立的新进入者，他们的组织架构是围绕一个人监督比如七个系统建立的。所以你可能就会开始看到市场营销专业毕业生的失业率增加两倍（达到原来的三倍）。</p><p>我不确定你会在软件工程师身上看到这种情况。我认为<strong>人工智能</strong>既会取代很多这类工作，也会创造很多这类工作，因为对软件的需求将大大增加。但你可能会在某些领域看到这种情况发生。</p><p>有太多的工作是在电脑前完成的。随着公司采纳了能为你做电脑工作的机器，这将改变他们的招聘策略。</p><p>你肯定听过有人思考过这个问题。你们（指政府官员）肯定讨论过这个。</p><p><strong>本·布坎南</strong>：我们确实在 23 年和 24 年与经济学家交谈，试图丰富这场辩论的细节。</p><p>现在的趋势线比那时更清晰。我们知道这不是 23 年和 24 年就能解决的问题。坦率地说，要对此采取任何有力的措施都需要国会参与，而那当时根本不在考虑之列。</p><p>——</p><p><strong>埃兹拉·克莱恩</strong>：所以这更多的是一种智力演练，而不是一项政策——</p><p><strong>本·布坎南</strong>：但政策始于智力演练。</p><p>——</p><p><strong>本·布坎南</strong>：当然，我认为这很公平。人工智能的一个优势，在某种程度上是一种反作用力——尽管我听到了你的观点，并且大部分同意你的论点——是它将增加个人的能动性。</p><p>所以我确实认为我们将进入这样一个世界：19 岁或 25 岁的人将能够使用系统来做他们以前无法做到的事情。就我们在此讨论的论点——即<strong>智能将在一定程度上变得更加商品化</strong>——而言，在那个世界里更突出的将是能动性和做事的能力。我认为总的来说，这可能带来一个相当有活力的经济。</p><p>而你所谈论的那种由小公司、充满活力的生态系统和激烈竞争构成的经济，在整体经济层面上看，其本身并非坏事。我想你我——也许还有<strong>万斯副总统</strong>——都同意的是，我们需要确保在转型中保护个体工人和工人阶层。</p><p>我认为我们应该坦诚地说：这将非常困难。我们在这方面从未做得很好。</p><p>——</p><p><strong>埃兹拉·克莱恩</strong>：我对此再同意不过了。在很大程度上，<strong>唐纳德·特朗普</strong>今天能当上总统，就是因为我们在对华（贸易/全球化影响）这事上搞砸了。</p><p>我之所以在这个问题上追问，是因为我们预见到这一点已经有一段时间了。但环顾四周，我没有看到多少有用的思考。我承认我们不知道它的具体形态。但至少，我希望看到一些备选方案，以便在颠覆性影响严重时我们知道该怎么做。</p><p>在这个国家，我们沉迷于一种经济上有用的叙事——即<strong>我们的成功掌握在自己手中</strong>——这使得我们很难在工人因自身无法掌控的原因（例如全球化带来的全球衰退或萧条）而被取代时，以同情心或现实主义的态度做出反应。</p><p>总有一些具备能动性和创造力的人变得超级高效。常常有这种情绪：看看他们。你为什么不能像他们一样？</p><p><strong>本·布坎南</strong>：我绝对不是这个意思。</p><p>——</p><p><strong>埃兹拉·克莱恩</strong>：我知道你不是这个意思。但这是根深蒂固的美国人看待经济的方式：你应该接受一些再培训。</p><p>所有这些人都要去当护士吗？有些事情是<strong>人工智能</strong>做不了的。我们需要多少水管工？实际上比我们现有的要多。但每个人都转行去做技工吗？</p><p>那些白宫里相信这一切即将到来的聪明人，你们进行的智力思考练习是什么？你们当时在说什么？</p><p><strong>本·布坎南</strong>：是的，我们在思考这个问题。我们知道这不是总统任期内需要面对的问题。我们知道这是一个需要国会才能采取任何行动的问题。</p><p>就你在这里表达的似乎是对现有答案的深切不满而言，我感同身受。我想我们很多人都感同身受。</p><p>你可以得到通常那些关于大量再培训的标准答案。但我也和你一样怀疑这是否是答案。你或许可以和一些<strong>硅谷的自由意志主义者</strong>或科技人士谈谈，他们会说：<strong>全民基本收入</strong>（universal basic income）。</p><p>我相信，而且我认为<strong>拜登总统</strong>也相信，<strong>工作带来一种尊严。这不必是有偿工作，但需要人们每天做一些能赋予他们意义的事情。</strong></p><p>就你对劳动力方面未来走向的不安而言，我感同身受。即使我不知道它的具体形态。</p><p>——</p><p><strong>埃兹拉·克莱恩</strong>：不仅如此，我想我对当前思考的质量感到不安。基本上是全面的，但尤其是在民主党这边——因为你在这里作为上届政府的代表。</p><p>我对<strong>特朗普政府</strong>有很多分歧，至少可以这么说。但我理解那些说：“看，<strong>埃隆·马斯克</strong>、<strong>大卫·萨克斯</strong>、<strong>马克·安德森</strong>、<strong>J.D. 万斯</strong>——特朗普政府最高层的人花了很多时间思考人工智能，并考虑过关于它的非常不寻常的想法”的人。</p><p>而且我认为民主党人有时在进行非同寻常的思考方面受到过多体制的约束。所以我理解你在出口管制、行政命令、人工智能安全研究所方面的观点。</p><p>但是，就民主党人自诩为工人阶级的政党而言，就我们多年来一直在谈论人工智能驱动的失业可能性而言，确实，当事情发生时，你需要国会。但你也需要能够转化为国会实施政策的思考。</p><p>所以我试图追问。难道没有讨论过吗？没有开过会吗？你们没有让 <strong>Claude</strong>（Anthropic 的人工智能助手）写一份选项简报吗？</p><p><strong>本·布坎南</strong>：嗯，我们肯定没有让 <strong>Claude </strong>写简报，因为我们首先得解决政府使用人工智能的问题。</p><p>——</p><p><strong>埃兹拉·克莱恩</strong>：看，但这本身就有点说明问题了。</p><p><strong>本·布坎南</strong>：埃兹拉，我同意政府基本上在所有这些方面都必须更具前瞻性。我的工作就是推动政府这样做。我认为在像政府使用人工智能这样的事情上，我们取得了一些进展。</p><p>所以我认为<strong>拜登政府</strong>没有人，尤其是我，会站出来说：我们解决了问题。</p><p>我们想说的是：我们正在为即将到来的事物奠定基础，它不会在我们执政期间到来，下一个团队将不得不，作为美国国家安全——以及在这种情况下，美国经济实力和繁荣——的问题，去应对它。</p><p>——</p><p><strong>埃兹拉·克莱恩</strong>：这正是我在关于人工智能的政策讨论中感到沮丧的地方。</p><p>你一开始就说，这可能是人类历史上最具变革性的技术，将在两到三年内落地。然后你说：哇，这听起来真是件大事。我们该怎么办？</p><p>就在这时，事情就变得有点模糊不清了。也许我们就是不知道。但我听你反复说了好几次的是：看，我们几乎没做什么来阻碍这项技术的发展。一切都是自愿的。我们唯一的要求是共享安全数据。</p><p>现在<strong>加速主义者</strong>来了。<strong>马克·安德森（Marc Andreessen）</strong>非常直白地批评了你们（指拜登政府）。</p><p>这场政策辩论到底有什么实质内容吗？难道仅仅是言辞上的情绪表达？如果这件事如此[脏话]重要，但除了或许是芯片出口管制之外，没有人能确切解释清楚我们到底需要做什么或讨论什么——难道是我们思考得不够有创造力吗？还是时机未到？将我们这次对话冷静、审慎的语调与我们讨论的起点（即 AGI 即将到来且事关重大）对比一下。</p><p><strong>本·布坎南</strong>：我认为这里应该有种理智上的谦逊。在你采取一项政策行动之前，你必须对你正在做什么以及为什么这样做有所理解。</p><p>所以，审视一项变革性技术，在图表上画出趋势线，并说这很快就会到来，同时却没有一个关于我们在 2027 年或 2028 年需要做什么的十四点计划，这在理智上是完全一致的。</p><p><strong>芯片管制</strong>之所以独特，是因为这是我们早期就能做的一件确凿无疑的好事，可以为我们争取到我之前谈到的空间。但我也认为，我们试图建立像人工智能安全研究所这样的机构，为新团队（无论是我们自己还是其他人）在管理这项技术方面取得成功奠定基础。</p><p>现在轮到他们（指<strong>特朗普政府</strong>）了，随着技术的到来，他们将不得不决定我们想如何在监管下进行校准。</p><p>——</p><p><strong>埃兹拉·克莱恩</strong>：你认为他们在未来两年内将不得不做出什么样的决策？</p><p><strong>本·布坎南</strong>：你提到了开源的问题。我猜测他们会如何决定。但那里存在着丰富的智识辩论。我们通过不采取任何行动的方式解决（暂时搁置）了它。他们将不得不决定是否要继续这样做。</p><p>最终，他们将不得不回答这个问题：公共部门和私营部门之间的关系是什么？例如，现在<strong>人工智能安全研究所</strong>的那些自愿性事务，将来是否会变成强制性的？</p><p>另一个关键决策是：我们试图以符合美国价值观的方式，推动<strong>人工智能</strong>在国防领域的应用。他们将不得不决定这该如何继续下去，以及他们是否想为了追求更快的速度而取消我们设置的一些保障措施。</p><p>所以我认为，在未来几年里，确实有一系列决策摆在他们面前需要做出，我们可以预见到这些决策即将到来，而无需我坐在这里说：我确切地知道 2027 年的答案会是什么。</p><p>——</p><p><strong>埃兹拉·克莱恩</strong>：那么，总是我们的最后一个问题：你会向听众/观众推荐哪三本书？</p><p><strong>本·布坎南</strong>：其中一本是<strong>托马斯·库恩（Thomas Kuhn）</strong>的<strong>《科学革命的结构》（The Structure of Scientific Revolutions）</strong>。这本书创造了<strong>“范式转移”（paradigm shift）</strong>这个术语，这基本上就是我们整个谈话一直在讨论的内容——<strong>技术和科学理解的转变及其对社会的影响</strong>。我喜欢<strong>库恩</strong>在这本写于 1960 年代的书中，如何提供了一系列历史案例和理论框架来思考<strong>范式转移</strong>。</p><p>另一本对我非常有价值的书是<strong>托马斯·瑞德（Thomas Rid）</strong>的<a target="_blank" rel="noopener noreferrer nofollow" class href="https://book.douban.com/subject/27039464/"><strong>《机器崛起：遗失的控制论历史》</strong></a><strong>（Rise of the Machines）</strong>，它讲述了那些曾经像我这样的书呆子的玩物的机器，如何在 70 年代和 80 年代变成了具有国家安全重要性的事物。我们在这里谈到了一些革命性技术——互联网、微处理器等等——它们正是从国家安全与技术发展这种交集中产生的。我认为这段历史应该为我们今天的工作提供借鉴。</p><p>然后最后一本书绝对是一本不寻常的书，但我认为它至关重要：<strong>乔治·桑德斯（George Saunders）</strong>的<a target="_blank" rel="noopener noreferrer nofollow" class href="https://book.douban.com/subject/36973145/"><strong>《漫游在雨中池塘》</strong></a><strong>（A Swim in the Pond in the Rain）</strong>。<strong>桑德斯</strong>是一位伟大的散文家、短篇小说家和小说家。他教授俄罗斯文学，在这本书中，他选取了七个俄罗斯文学短篇故事，并对它们进行了文学解读。</p><p>这本书让我印象深刻的是，它根本上是我能想到的最富人性的努力：他选取了伟大的人类短篇故事，并对这些故事的意义给出了现代的诠释。当我们谈论那些距离机器能够完成还有很长距离的认知任务时，我希望，在某种程度上，这就是其中之一——<strong>有些根本上属于人类的东西，只有我们能做</strong>。我不确定这是否是真的，但我希望是真的。</p><p>——</p><p><strong>埃兹拉·克莱恩</strong>：我得说，我因为那本书请<strong>桑德斯</strong>上过节目（<a target="_blank" rel="noopener noreferrer nofollow" class href="https://www.nytimes.com/2021/02/19/opinion/ezra-klein-podcast-george-saunders.html"><strong>What It Means to Be Kind in a Cruel World</strong></a>）。那是我最喜欢的节目之一。大家应该去看看。</p><p>本·布坎南，非常感谢你。</p><p><strong>本·布坎南</strong>：谢谢邀请。</p><p>原文：<a target="_blank" rel="noopener noreferrer nofollow" class href="https://www.nytimes.com/2025/03/04/opinion/ezra-klein-podcast-ben-buchanan.html">The Government Knows A.G.I. Is Coming</a> By Ezra Klein</p>
